{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "de1d9e9f-96b6-497b-805a-c335f9b882b8",
    "_uuid": "291b5ef28fe537e33171f1e5bf7b1b2f23600952"
   },
   "source": [
    "# Gibbs Sampling\n",
    "\n",
    "Similar to another [collaborative_filtering.ipynb](https://github.com/liyenhsu/restaurant-data-with-consumer-ratings/blob/master/collaborative_filtering.ipynb) in this repository, here we also use a matrix factorization-based model. However, instead of optimizing a cost function, we will use [Gibbs sampling](https://en.wikipedia.org/wiki/Gibbs_sampling), a Markov chain Monte Carlo (MCMC) algorithm, to sample the posterior distribution over the unknown parameters (how much we know about these quantities given the data we observe) and then use their means as the optimal parameter values. [Reference](https://github.com/cs109/content/blob/master/HW4_solutions.ipynb).\n",
    "<br><br>\n",
    "All the steps before the modeling part in this notebook are simply copied from [collaborative_filtering.ipynb](https://github.com/liyenhsu/restaurant-data-with-consumer-ratings/blob/master/collaborative_filtering.ipynb). In order to compare the results here with what we got from the other methods, we process and split the data in the same way. Please refer to that notebook for the explanation of these steps.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "f368523d-9435-45de-a458-04ed5202342b",
    "_uuid": "3588092b447848f3682e38030fbf5944591554e0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rating = pd.read_csv('data/rating_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ba0bb5c5-15bc-4b56-bb9c-18d546b84ce1",
    "_uuid": "7828d58da4e7588a685c2bbdf49e6c7546a6b0b7"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "7b93bcd3-ff59-42f9-a18a-f51763b706f6",
    "_uuid": "42ab37c990bbae9792cb61274ff9b804d0321673"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>placeID</th>\n",
       "      <th>rating</th>\n",
       "      <th>food_rating</th>\n",
       "      <th>service_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U1077</td>\n",
       "      <td>135085</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U1077</td>\n",
       "      <td>135038</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U1077</td>\n",
       "      <td>132825</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U1077</td>\n",
       "      <td>135060</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U1068</td>\n",
       "      <td>135104</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userID  placeID  rating  food_rating  service_rating\n",
       "0  U1077   135085       2            2               2\n",
       "1  U1077   135038       2            2               1\n",
       "2  U1077   132825       2            2               2\n",
       "3  U1077   135060       1            2               2\n",
       "4  U1068   135104       1            1               2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "6f38b578-4c25-435c-a5d9-082bef3cf916",
    "_uuid": "0aa7f5737b64c42de5a11f95f39388f92f1398cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 138 unique userID's.\n",
      "There are 130 unique placeID's.\n",
      "There are 1161 * 3 ratings.\n"
     ]
    }
   ],
   "source": [
    "n_user = len(rating.userID.unique())\n",
    "n_res = len(rating.placeID.unique())\n",
    "n_rating = len(rating)\n",
    "\n",
    "print(\"There are {} unique userID's.\".format(n_user))\n",
    "print(\"There are {} unique placeID's.\".format(n_res))\n",
    "print(\"There are {} * 3 ratings.\".format(n_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "353d57a1-80ef-4a5e-b857-4cc9ea376e8d",
    "_uuid": "b78d75dfe83b5ad3845099819d44ee4c6d3c20ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>food_rating</th>\n",
       "      <th>service_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1161.000000</td>\n",
       "      <td>1161.000000</td>\n",
       "      <td>1161.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.199828</td>\n",
       "      <td>1.215332</td>\n",
       "      <td>1.090439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.773282</td>\n",
       "      <td>0.792294</td>\n",
       "      <td>0.790844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rating  food_rating  service_rating\n",
       "count  1161.000000  1161.000000     1161.000000\n",
       "mean      1.199828     1.215332        1.090439\n",
       "std       0.773282     0.792294        0.790844\n",
       "min       0.000000     0.000000        0.000000\n",
       "25%       1.000000     1.000000        0.000000\n",
       "50%       1.000000     1.000000        1.000000\n",
       "75%       2.000000     2.000000        2.000000\n",
       "max       2.000000     2.000000        2.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.iloc[:,2:].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "04237c0c-47a7-4d47-b965-736d748a026b",
    "_uuid": "725e60c128515d6d3b313900b39518a36b2e92db",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "placeID = np.sort(rating.placeID.unique()) # All the placeID's\n",
    "userID = np.sort(rating.userID.unique())   # All the userID's\n",
    "\n",
    "Y_overall = pd.DataFrame(np.zeros((n_res,n_user))-1, columns=userID, index=placeID)\n",
    "Y_food = Y_overall.copy()\n",
    "Y_service = Y_overall.copy() \n",
    "\n",
    "for p, u, o, f, s in zip(rating.placeID, rating.userID, rating.rating, rating.food_rating, \n",
    "                         rating.service_rating):\n",
    "    Y_overall.loc[p,u] = o\n",
    "    Y_food.loc[p,u] = f\n",
    "    Y_service.loc[p,u] = s\n",
    "\n",
    "Y_overall = Y_overall.values\n",
    "Y_food = Y_food.values\n",
    "Y_service = Y_service.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "f9398dd1-d673-4845-b94f-1c59805066ea",
    "_uuid": "4d70cc2a98852c666489d8e033c1e5097a5fbd1a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = np.zeros(Y_overall.shape)\n",
    "R[Y_overall >= 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5279a84f-15da-4986-bb80-8fd4e7b78024",
    "_uuid": "09fd95060b9d2ebcb0ee353b54bec6d4029ed4af"
   },
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "2318903a-d2f5-4fa8-99e1-6cd448dff888",
    "_uuid": "6d5dc50580c48610b191f86ff5d748f90e8dac48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(810.0, 351.0)\n"
     ]
    }
   ],
   "source": [
    "# 30% of the existing ratings will be used as the test set, so during \n",
    "# the training, they will be flagged. \n",
    "#\n",
    "# The minimum number of ratings from a user = 3. In such a case, it \n",
    "# will be a 2/1 split.\n",
    "\n",
    "random.seed(99)\n",
    "cond = True\n",
    "\n",
    "while cond:\n",
    "\n",
    "    R_train = R.copy()\n",
    "\n",
    "    # loop over each user\n",
    "    for i in range(R_train.shape[1]):\n",
    "        # the restaurants that are rated\n",
    "        index = list( np.where(R_train[:,i] == 1)[0] )  \n",
    "        # randomly select about 30% of them to be flagged\n",
    "        flag = int(round(len(index)*0.3))\n",
    "        index_flag = random.sample(index,flag)\n",
    "        R_train[index_flag,i] = 0  \n",
    "    \n",
    "    # make sure in the traning set, each restaurant also has at least \n",
    "    # 2 ratings\n",
    "    if np.sum(R_train,axis=1).min() > 1: \n",
    "        cond = False\n",
    "\n",
    "# the rest will be the test set        \n",
    "R_test = R - R_train\n",
    "\n",
    "# Now \"R_train\" contains 810 ones and \"R_test\" contains 351 ones (\"R\" contains 1161 ones)\n",
    "print(R_train.sum(), R_test.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "82e3fed9-e56f-44aa-bbbe-3dc41154a84a",
    "_uuid": "a903ddff904fbcb554094b0bf2254642b07df606"
   },
   "source": [
    "## Evaluation Metrics ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "48202bad-5f64-493a-a360-97af80310f5a",
    "_uuid": "73040c76236c1625a8185c8b3f479c2b38f1db22",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSE(Y,Y_pred,R):\n",
    "    \n",
    "    return np.sqrt(mean_squared_error(Y[R  == 1], Y_pred[R == 1]))\n",
    "\n",
    "\n",
    "def FCP(Y,Y_pred,R,verbose=True):\n",
    "    \n",
    "    # list of true ratings from each user (we only select users with at least two ratings)\n",
    "    Y_fcp = []  \n",
    "    Y_pred_fcp = [] # list of predicted ratings from each user \n",
    "    n_user = R.shape[1]\n",
    "    \n",
    "    for i in range(n_user):\n",
    "        \n",
    "        cond = (R.sum(axis=0) >= 2)[i] # there should be at least two ratings from a user\n",
    "        index = np.where( R[:,i] == 1)[0] # the indices (restaurants) with ratings\n",
    "    \n",
    "        if cond:\n",
    "            \n",
    "            Y_fcp.append( (Y*R)[:,i][index] )\n",
    "            Y_pred_fcp.append( (Y_pred*R)[:,i][index] )\n",
    "\n",
    "        \n",
    "    n_fcp = len(Y_fcp) # number of users with at least two ratings\n",
    "    TP = 0. # Total number of pairs\n",
    "    DP = 0. # number of discordant pairs\n",
    "    CP = 0. # number of concordant pairs (excluding ties)\n",
    "    \n",
    "    for i in range(n_fcp):\n",
    "        \n",
    "        num_Y = len(Y_fcp[i])   # number of ratings from a user\n",
    "        TP += num_Y*(num_Y-1)/2 # number of rating pairs = n*(n+1)/2 \n",
    "\n",
    "        greater = np.array([])\n",
    "        greater_pred = np.array([])\n",
    "\n",
    "        # this loop is to go over all the rating pairs\n",
    "        for j in range(num_Y-1):\n",
    "            \n",
    "            not_equal = Y_fcp[i][j] != Y_fcp[i][j+1:]\n",
    "            greater = Y_fcp[i][j] > Y_fcp[i][j+1:]\n",
    "            greater_pred = Y_pred_fcp[i][j] > Y_pred_fcp[i][j+1:]\n",
    "\n",
    "            # filter the ones that are not ties\n",
    "            greater = greater[not_equal]\n",
    "            greater_pred = greater_pred[not_equal]\n",
    "\n",
    "            DP += (greater != greater_pred).sum()\n",
    "            CP += (greater == greater_pred).sum()\n",
    "            \n",
    "    if verbose:        \n",
    "        print(\"Total number of rating pairs: {}\".format(int(TP)))\n",
    "        print(\"Total number of discordant pairs: {}\".format(int(DP)))\n",
    "        print(\"Total number of concordant pairs: {}\".format(int(CP)))\n",
    "        print(\"Total number of ties: {}\".format(int(TP-DP-CP)))\n",
    "        print(\"FCP: {}\".format(CP/(CP+DP)))\n",
    "    \n",
    "    #return CP/(CP+DP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "1849df13-fa7c-4f31-b01f-f0b4d7e0b265",
    "_uuid": "8147c921a5d5f90d427fb989e032ae9b46b39e7e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A plotter to make boxplot\n",
    "def MakeBoxplot(Y_pred, Y_true, R, title):\n",
    "    \n",
    "    data1 = Y_pred[R == 1][Y_true[R == 1] == 0]\n",
    "    data2 = Y_pred[R == 1][Y_true[R == 1] == 1]\n",
    "    data3 = Y_pred[R == 1][Y_true[R == 1] == 2]\n",
    "    data = [data1,data2,data3]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.boxplot(data)\n",
    "    plt.xticks([1, 2, 3],[0,1,2])\n",
    "    plt.xlabel('True Rating')\n",
    "    plt.ylabel('Predicted Rating')   \n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cc78beac-45f8-41b1-9c8a-a362bab475ea",
    "_uuid": "54e1fb479edd9303ba44991a602a0b9252c45bca"
   },
   "source": [
    "## Model\n",
    "\n",
    "#### Overview ####\n",
    "\n",
    "We will again use a matrix factorization-based model, also known as a latent factor model. We can think of latent factors as properties of restaurants (e.g., spiciness of food or price) that users have a positive or negative preference for. We do not observe these factors or the users' preferences directly, but we assume that they affect how users tend to rate restaurants. For example, if a restaurant serves a lot of spicy food and a user dislikes spicy food, then the restaurant would have a high \"spiciness\" factor, and the user would have a strongly negative preference, resulting in a prediction of a low rating. Note that if users have similar preferences, then according to the model, they will behave similarly, and likewise, if restaurants have similar latent factors, they will be rated similarly by similar users. Latent factors thus give us an intuitive way to specify a generative model the obeys the central dogma. One issue that comes up with latent factor models is determining how many latent factors to include. In other words, it is a hyperparameter that we need to tune.\n",
    "\n",
    "#### Rating Model Specification ####\n",
    "\n",
    "To make this model concrete, we can write down our probability model as a generative process. First, we define the following quantities:\n",
    "\n",
    "Counts:\n",
    "\n",
    "* $L$: The number of latent factors.\n",
    "\n",
    "* $U$: The number of users.\n",
    "\n",
    "* $M$: The number of items (restaurants).\n",
    "\n",
    "* $N$: The number of observed ratings.\n",
    "\n",
    "Data:\n",
    "\n",
    "* $Y_{um}$: The star rating given to restaurant $m$ by user $u$.\n",
    "* $Y$: The full collection of observed star ratings.\n",
    "\n",
    "Item-specific quantities:\n",
    "\n",
    "* $\\gamma_m$: An item-specific parameter vector of length $L+1$. The first element of $\\gamma_m$, denoted $\\gamma_m[0]$ is the item-specific bias. The remaining $L$ elements of $\\gamma_m$, denoted $\\gamma_m[1:]$, are the latent factors associated with item $m$.\n",
    "\n",
    "* $\\Gamma$: An $M$ by $L+1$ matrix where the $m$th row is $\\gamma_m$.\n",
    "\n",
    "User-specific quantities:\n",
    "\n",
    "* $\\theta_u$: A user-specific parameter vector of length $L+1$. The first element of $\\theta_u$, denoted $\\theta_u[0]$ is the user-specific bias. The remaining $L$ elements of $\\theta_u$, denoted $\\theta_u[1:]$, are user $u$'s preferences for the latent factors.\n",
    "\n",
    "* $\\Theta$: A $U$ by $L+1$ matrix where the $u$th row is $\\theta_u$.\n",
    "\n",
    "Global quantities:\n",
    "\n",
    "* $\\mu$: The overall ratings mean.\n",
    "\n",
    "* $\\sigma$: The residual variance of ratings after the mean, bias terms, and latent factors have been taken into account.\n",
    "\n",
    "Using these quantities, we can specify our model for each rating $Y_{um}$ similarly to a linear regression:\n",
    "\n",
    "$$Y_{um} = \\mu + \\theta_{u}[0] + \\gamma_{m}[0] + \\theta_{u}[1:]^{\\top}\\gamma_{m}[1:] + \\epsilon_{um}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\epsilon_{um} \\sim N(0, \\sigma).$$\n",
    "\n",
    "Note that while this looks like a linear regression, it is of a slightly different form because the latent factor term involves the product of two unknowns. This is like a linear regression where we forgot to measure some covariates.\n",
    "\n",
    "We also assume the following priors on the user-specific and item-specific parameters:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\gamma_m &\\sim MVN(\\mathbf 0, \\Lambda_\\gamma^{-1})\\\\\n",
    "\\theta_u &\\sim MVN(\\mathbf 0, \\Lambda_\\theta^{-1}),\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $MVN$ means multivariate normal, $\\mathbf 0$ is vector of length $L+1$ filled with zeros, and $\\Lambda_\\theta^{-1}$ and $\\Lambda_\\gamma^{-1}$ are $L+1 \\times L+1$ covariance matrices. $\\mu$ and $\\sigma$ also have priors, but they are not relevant to our task.\n",
    "\n",
    "#### Goal for this Model ####\n",
    "Using this model, we want to make inference about all of the quantities that, if we knew them, would allow us to sample $Y_{um}$ for any user and any item. These quantities are $\\mu$, $\\sigma$, and the elements of $\\Theta$ and $\\Gamma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs Sampling\n",
    "\n",
    "Our goal is to compute the posterior distribution over the unknowns $\\mu$, $\\sigma$, $\\Gamma$, and $\\Theta$ given $Y$, which reflects how much we know about these quantities given the data we have observed. We write this distribution as $P(\\mu, \\sigma, \\Gamma, \\Theta \\mid Y)$. The most general way to learn about the posterior distribution is to sample from it. This can be challenging, particularly in problems that are very high dimensional. One strategy for for sampling from high-dimensional distributions is Gibbs sampling.\n",
    "\n",
    "Gibbs sampling breaks down the posterior probability distribution into blocks of unknowns, and samples iteratively from each block assuming that the values of the other blocks (and the data) are known and fixed. In this case, we will break down the posterior distribution into blocks of $\\mu$, $\\sigma$, each vector $\\gamma_m$, and each vector $\\theta_u$. \n",
    "\n",
    "#### Distribution of $\\gamma_{m'}$ given $Y, \\mu, \\sigma, \\Gamma_{-m'}, \\Theta$####\n",
    "\n",
    "Intuitively, this is the distribution of the item-specific parameters for item $m'$, imagining that all of the other unknowns are fixed.\n",
    "\n",
    "More precisely, we want to draw from the distribution of $\\gamma_{m'}$ conditional on the data $Y$ and all other unknowns -- that is, $\\mu$, $\\sigma$, all of $\\Theta$, and all of $\\Gamma$ except for $\\gamma_{m'}$, which we denote $\\Gamma_{-m'}$.\n",
    "\n",
    "Note that in the model specification above, the only places that $\\gamma_{m'}$ appears are in the regression equations for each $Y_{um}$ that involves item $m'$. If we write out just these equations, we get a system of the following form,\n",
    "\n",
    "$$Y_{um'} = \\mu + \\theta_{u}[0] + \\gamma_{m'}[0] + \\theta_{u}[1:]^{\\top}\\gamma_{m'}[1:] + \\epsilon_{um'},$$\n",
    "\n",
    "with one equation for each $u$ that rated item $m'$. Now, because \n",
    "\n",
    "If we move all of the fully known terms to the left-hand side, we obtain the system:\n",
    "\n",
    "$$Y_{um'} - \\mu - \\theta_{u}[0] = \\gamma_{m'}[0] + \\theta_{u}[1:]^{\\top}\\gamma_{m'}[1:] + \\epsilon_{um'}.$$\n",
    "\n",
    "Notice that, because we assume that $\\theta_{u}$ is known, this equation now fits cleanly into the form of a linear regression, where $\\gamma_{m'}$ is the vector of unknown coefficients. This means that the posterior distribution for $\\gamma_{m'}$ conditional on everything else is the same as the posterior for the coefficients of a Bayesian linear regression of $(Y_{um'} - \\mu - \\theta_{u}[0])$ on $\\theta_{u}[1:]$ and an intercept.\n",
    "\n",
    "Let's denote the set of users who rated item $m'$ as $(u_1, \\cdots, u_g)$. Then, we can define the following vector and matrix:\n",
    "\n",
    "\\begin{align*}\n",
    "Y_{m'} = \\left(\\begin{array}{c} Y_{u_1m'}-\\mu-\\theta_{u_1}[0]\\\\ \\vdots \\\\ Y_{u_gm'}-\\mu-\\theta_{u_g}[0]\\end{array}\\right), \\qquad\n",
    "X_{m'} &= \\left(\\begin{array}{cc} 1 & \\theta_{u_1}[1:]^\\top \\\\ \\vdots & \\vdots \\\\ 1 & \\theta_{u_g}[1:]^\\top\\end{array}\\right),\n",
    "\\end{align*}\n",
    "\n",
    "where $Y_{m'}$ is a vector of length $g$ and $X_{m'}$ is a $g \\times L+1$ matrix.\n",
    "\n",
    "The draw from $\\gamma_{m'}$ given everything else then has the form:\n",
    "$$ \\gamma_{m'} \\mid Y, \\mu, \\sigma, \\Gamma_{-m'}, \\Theta \\sim MVN\\left(Q_{m'}^{-1} \\frac{1}{\\sigma^2}X_{m'}^\\top Y_{m'}, Q_{m'}^{-1}\\right)$$\n",
    "where\n",
    "$$ Q_{m'} = \\left(\\frac{1}{\\sigma^2}X_{m'}^\\top X_{m'} + \\Lambda_\\gamma\\right).$$\n",
    "\n",
    "#### Distribution of $\\theta_{u'}$ given $Y, \\mu, \\sigma, \\Gamma, \\Theta_{-u'}$####\n",
    "\n",
    "Intuitively, this is the distribution of the user-specific parameters for user $u'$, imagining that all of the other unknowns are fixed.\n",
    "\n",
    "We can use a very similar argument to the one above. We can denote the set of items rated by user $u'$ as $(m_1, \\cdots, m_g)$ and define the vector and matrix:\n",
    "\n",
    "\\begin{align*}\n",
    "Y_{u'} = \\left(\\begin{array}{c} Y_{u'm_1}-\\mu-\\gamma_{m_1}[0] \\\\ \\vdots \\\\ Y_{u'm_g}-\\mu-\\gamma_{m_g}[0]\\end{array}\\right), \\qquad\n",
    "X_{u'} &= \\left(\\begin{array}{cc} 1 & \\gamma_{m_1}[1:]^\\top \\\\ \\vdots & \\vdots \\\\ 1 & \\gamma_{m_g}[1:]^\\top\\end{array}\\right),\n",
    "\\end{align*}\n",
    "\n",
    "where $Y_{u'}$ is a vector of length $g$ and $X_{u'}$ is a $g \\times L+1$ matrix.\n",
    "\n",
    "the draw from $\\theta_{u'}$ given everything else has the form:\n",
    "$$ \\theta_{u'} \\mid Y, \\mu, \\sigma, \\Gamma, \\Theta_{-u'} \\sim MVN\\left(Q_{u'}^{-1} \\frac{1}{\\sigma^2}X_{u'}^\\top Y_{u'}, Q_{u'}^{-1}\\right)$$\n",
    "where\n",
    "$$ Q_{u'}= \\left(\\frac{1}{\\sigma^2}X_{u'}^\\top X_{u'} + \\Lambda_\\theta\\right).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "gamma_m_draw\n",
    "\n",
    "Draw a single sample from the conditional posterior distribution\n",
    "of gamma_m.\n",
    "\n",
    "Inputs\n",
    "-------\n",
    "X_m: A g-by-L+1 matrix, defined above. \n",
    "Y_m: A 1D vector of length g, defined above.\n",
    "sig2: Residual _variance_, as defined above.\n",
    "Lambda_gamma: Prior precision matrix.\n",
    "\n",
    "Outputs\n",
    "--------\n",
    "Single draw from conditional posterior, defined above.\n",
    "\"\"\"\n",
    "#Item-specific parameters given all else\n",
    "def gamma_m_draw(X_m, Y_m, sig2, Lambda_gamma):\n",
    "\n",
    "    #Compute matrices that define conditional posterior.\n",
    "    Q_m_inv = np.linalg.inv(np.dot(X_m.T, X_m)/sig2+Lambda_gamma)\n",
    "    XtY = np.dot(X_m.T, Y_m)\n",
    "\n",
    "    #Draw item-specific parameters.\n",
    "    return np.random.multivariate_normal(np.dot(Q_m_inv, XtY)/sig2, Q_m_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "theta_u_draw\n",
    "\n",
    "Draw a single sample from the conditional posterior distribution\n",
    "of gamma_m.\n",
    "\n",
    "Inputs\n",
    "-------\n",
    "X_u: A g-by-L+1 matrix, defined above. \n",
    "Y_u: A 1D vector of length g, defined above.\n",
    "sig2: Residual _variance_, as defined above.\n",
    "Lambda_theta: Prior precision matrix.\n",
    "\n",
    "Outputs\n",
    "--------\n",
    "Single draw from conditional posterior, defined above.\n",
    "\"\"\"\n",
    "#User-specific parameters given all else\n",
    "def theta_u_draw(X_u, Y_u, sig2, Lambda_theta):\n",
    "    #Compute matrices that define conditional posterior.\n",
    "    Q_u_inv = np.linalg.inv(np.dot(X_u.T, X_u)/sig2+Lambda_theta)\n",
    "    XtY = np.dot(X_u.T, Y_u)\n",
    "    \n",
    "    #Draw the user-specific parameters\n",
    "    return np.random.multivariate_normal(np.dot(Q_u_inv, XtY)/sig2, Q_u_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "factor_gibbs\n",
    "\n",
    "Runs a gibbs sampler to infer mean, variance, user-specific, and item-specific\n",
    "parameters.\n",
    "\n",
    "Inputs\n",
    "-------\n",
    "data: A dataframe containing ratings data.\n",
    "L: Dimension of latent factors.\n",
    "maxit: Number of samples to draw from posterior.\n",
    "Lambda_theta_diag: Hyperparameter controlling regularization of Theta.\n",
    "Lambda_gamma_diag: Hyperparameter controlling regularization of Gamma.\n",
    "\n",
    "Outputs\n",
    "--------\n",
    "Dictionary with elements\n",
    "mu: Draws of mu. 1D array of length maxiter.\n",
    "sig2: Draws of sig2, residual variance. 1D array of length maxiter.\n",
    "theta: Draws of Theta. U-by-L-by-maxiter array.\n",
    "gamma: Draws of Gamma. M-by-L-by-maxiter array.\n",
    "\"\"\"\n",
    "def factor_gibbs(data, L, maxit, Lambda_theta_diag, Lambda_gamma_diag):\n",
    "    data = data.copy()\n",
    "    N = data.shape[0]\n",
    "\n",
    "    #Create indices that allow us to map users and restaurants to rows\n",
    "    #in parameter vectors.\n",
    "    uusers, uidx = np.unique(data.userID, return_inverse=True)\n",
    "    uitems, midx = np.unique(data.placeID, return_inverse=True)\n",
    "\n",
    "    nusers = uusers.size\n",
    "    nitems = uitems.size\n",
    "\n",
    "    #Add numerical indices to dataframe.\n",
    "    data[\"uidx\"] = uidx\n",
    "    data[\"midx\"] = midx\n",
    "\n",
    "    #Group observations by user and by business.\n",
    "    ugroups = data.groupby(\"uidx\")\n",
    "    mgroups = data.groupby(\"midx\")\n",
    "\n",
    "    all_avg = data.rating.mean()\n",
    "    u_avg = ugroups.rating.mean()\n",
    "    m_avg = mgroups.rating.mean()\n",
    "\n",
    "    #Initialize parameters and set up data structures for\n",
    "    #holding draws.\n",
    "    #Overall mean\n",
    "    mu = all_avg\n",
    "    mu_draws = np.zeros(maxit)\n",
    "    #Residual variance\n",
    "    sig2 = 0.5\n",
    "    sig2_draws = np.zeros(maxit)\n",
    "\n",
    "    #Matrix of user-specific bias and L latent factors.\n",
    "    theta = np.zeros([nusers, L+1])\n",
    "    theta[:,0] = u_avg-all_avg\n",
    "    theta_draws = np.zeros([nusers, L+1, maxit])\n",
    "\n",
    "    #Matrix of item-specific bias and L latent factors.\n",
    "    gamma = np.zeros([nitems, L+1])\n",
    "    gamma[:,0] = m_avg-all_avg\n",
    "    gamma_draws = np.zeros([nitems, L+1, maxit])\n",
    "\n",
    "    #Matrix for holding the expected number of stars\n",
    "    #for each observation at each draw from the posterior.\n",
    "    EY_draws = np.zeros([data.shape[0], maxit])\n",
    "\n",
    "    #Inverse covariance matrices from the prior on each theta_u\n",
    "    #and gamma_b. These are diagonal, like Ridge regression.\n",
    "    Lambda_theta = np.eye(L+1)*Lambda_theta_diag\n",
    "    Lambda_gamma = np.eye(L+1)*Lambda_gamma_diag\n",
    "\n",
    "    np.random.seed(0)\n",
    "    #Main sampler code\n",
    "    for i in range(maxit):\n",
    "        if (i+1)%100 == 0: print(\"{} iterations\".format(i+1))\n",
    "            \n",
    "        #The entire regression equation except for the overall mean.\n",
    "        nomu = np.sum(theta[data.uidx,1:]*gamma[data.midx,1:], axis=1) +\\\n",
    "                  theta[data.uidx,0] + gamma[data.midx,0]    \n",
    "\n",
    "        #Draw overall mean from a normal distribution\n",
    "        mu = np.random.normal(np.mean(data.rating-nomu), np.sqrt(sig2/N))\n",
    "        #Draw overall residual variance from a scaled inverse-Chi squared distribution.\n",
    "        sig2 = np.sum(np.power(data.rating-nomu-mu,2))/np.random.chisquare(N-2)\n",
    "        \n",
    "        #For each item\n",
    "        for mi,itemdf in mgroups:\n",
    "            #Gather relevant observations, and subtract out overall mean and\n",
    "            #user-specific biases, which we are holding fixed.\n",
    "            Y_m = itemdf.rating-mu-theta[itemdf.uidx,0]\n",
    "            #Build the regression design matrix implied by holding user factors\n",
    "            #fixed.\n",
    "            X_m = np.hstack((np.ones([itemdf.shape[0],1]),\n",
    "                             theta[itemdf.uidx,1:]))\n",
    "            gamma[mi,:] = gamma_m_draw(X_m, Y_m, sig2, Lambda_gamma)\n",
    "            \n",
    "        #For each user\n",
    "        for ui,userdf in ugroups:\n",
    "            #Gather relevant observations, and subtract out overall mean and\n",
    "            #business-specific biases, which we are holding fixed.\n",
    "            Y_u = userdf.rating-mu-gamma[userdf.midx,0]\n",
    "            #Build the regression design matrix implied by holding business factors\n",
    "            #fixed.\n",
    "            X_u = np.hstack((np.ones([userdf.shape[0],1]),\n",
    "                             gamma[userdf.midx,1:]))\n",
    "            \n",
    "            theta[ui,:] = theta_u_draw(X_u, Y_u, sig2, Lambda_theta)\n",
    "\n",
    "        #Record draws\n",
    "        mu_draws[i] = mu\n",
    "        sig2_draws[i] = sig2\n",
    "        theta_draws[:,:,i] = theta\n",
    "        gamma_draws[:,:,i] = gamma\n",
    "\n",
    "    return {\"mu\": mu_draws, \"sig2\": sig2_draws,\n",
    "            \"theta\": theta_draws, \"gamma\": gamma_draws}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above ``factor_gibbs`` function takes as input a data frame with three columns, ``userID``, ``placeID``, and ``rating``,  so we transform our training set to this form and then feed it to ``factor_gibbs``. Again, we will only predict the overall ratings, as the procedures for the other two ratings are exactly the same anyway. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "63d2e81e-530c-4051-8af3-50692096457d",
    "_uuid": "cc8e898f8223e9175f50789ac1f5915e425d038e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = Y_overall \n",
    "\n",
    "uID = []\n",
    "pID = []\n",
    "r = []\n",
    "\n",
    "for i in range(R.shape[1]):\n",
    "    for j in range(R.shape[0]):\n",
    "        if R_train[j,i] == 1:\n",
    "            pID.append(placeID[j])\n",
    "            uID.append(userID[i])\n",
    "            r.append(Y[j,i])\n",
    "\n",
    "rating_train = pd.DataFrame({'userID':uID, 'placeID':pID, 'rating':r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have posterior draws from the sampler, the most natural thing to do is to compute the posterior mean of each quantity you are intersted in. To do this, we simply need to take the average value of each quantity across the samples drawn from the sampler. However, we will want to ignore the first 20-30% of samples because these correspond the **burnin period**, the time during which the sampler is still looking for the main meat of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict the ratings for all the restaurant-user pairs\n",
    "def predict(gibbs_out, burnin):\n",
    "    mu = gibbs_out['mu']\n",
    "    theta0 = gibbs_out['theta'][:,0,:]\n",
    "    gamma0 = gibbs_out['gamma'][:,0,:]\n",
    "    theta = gibbs_out['theta'][:,1:,:]\n",
    "    gamma = gibbs_out['gamma'][:,1:,:]    \n",
    "    maxit = len(mu)\n",
    "    \n",
    "    Y_draws = np.zeros((n_res,n_user,maxit))\n",
    "    for i in range(maxit):\n",
    "        # predicted ratings from each draw (the vectorized version of the regression equation)\n",
    "        Y_draws[:,:,i] = mu[i] + theta0[:,i].reshape(1,n_user) + gamma0[:,i].reshape(n_res,1) +\\\n",
    "                         np.dot(gamma[:,:,i], theta[:,:,i].T)\n",
    "\n",
    "    # average the results, eliminating the first n = burnin samples.        \n",
    "    Y_pred = np.mean(Y_draws[:,:,burnin:], axis=-1)\n",
    "    return Y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can draw 1000 samples from the posterior distribution using a two-dimensional latent factor (``L = 2``) and prior precisions `Lambda_theta_diag` and `Lambda_gamma_diag` both equal to 0.1. This is the model which I found to give the best result. To compute the posterior mean of the fitted values, we eliminate the first 200 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 iterations\n",
      "200 iterations\n",
      "300 iterations\n",
      "400 iterations\n",
      "500 iterations\n",
      "600 iterations\n",
      "700 iterations\n",
      "800 iterations\n",
      "900 iterations\n",
      "1000 iterations\n"
     ]
    }
   ],
   "source": [
    "gibbs_out = factor_gibbs(rating_train, 2, 1000, 0.1, 0.1)\n",
    "Y_pred_gibbs = predict(gibbs_out, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the training set: 0.159773792888\n",
      "RMSE of the test set: 0.782432756717\n"
     ]
    }
   ],
   "source": [
    "# RMSE\n",
    "print(\"RMSE of the training set: {}\".format(RMSE(Y,Y_pred_gibbs,R_train)))\n",
    "print(\"RMSE of the test set: {}\".format(RMSE(Y,Y_pred_gibbs,R_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "Total number of rating pairs: 2380\n",
      "Total number of discordant pairs: 1\n",
      "Total number of concordant pairs: 1054\n",
      "Total number of ties: 1325\n",
      "FCP: 0.999052132701\n",
      "\n",
      "\n",
      "Test Set:\n",
      "Total number of rating pairs: 339\n",
      "Total number of discordant pairs: 46\n",
      "Total number of concordant pairs: 87\n",
      "Total number of ties: 206\n",
      "FCP: 0.654135338346\n"
     ]
    }
   ],
   "source": [
    "# FCP\n",
    "print(\"Training Set:\")\n",
    "FCP(Y,Y_pred_gibbs,R_train)\n",
    "print(\"\\n\")\n",
    "print(\"Test Set:\")\n",
    "FCP(Y,Y_pred_gibbs,R_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bf75e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MakeBoxplot(Y_pred_gibbs, Y, R_train, 'Training Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEWCAYAAABmE+CbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCJKkxv8H4CbVT7i5SfgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112819d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MakeBoxplot(Y_pred_gibbs, Y, R_test, 'Test Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The FCP (87/133) for the test set is similar to what we got in [collaborative_filtering.ipynb](https://github.com/liyenhsu/restaurant-data-with-consumer-ratings/blob/master/collaborative_filtering.ipynb) (86/133). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
